{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1bff5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "from models import *\n",
    "from torchsummary import summary\n",
    "device =torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e56bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.vgg11(pretrained=True).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584945fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU(inplace=True)\n",
       "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (12): ReLU(inplace=True)\n",
       "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (14): ReLU(inplace=True)\n",
       "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (19): ReLU(inplace=True)\n",
       "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f01a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet16().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f041d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 768, 768]           1,792\n",
      "            Conv2d-2         [-1, 64, 768, 768]           1,792\n",
      "              ReLU-3         [-1, 64, 768, 768]               0\n",
      "              ReLU-4         [-1, 64, 768, 768]               0\n",
      "              ReLU-5         [-1, 64, 768, 768]               0\n",
      "              ReLU-6         [-1, 64, 768, 768]               0\n",
      "              ReLU-7         [-1, 64, 768, 768]               0\n",
      "              ReLU-8         [-1, 64, 768, 768]               0\n",
      "            Conv2d-9         [-1, 64, 768, 768]          36,928\n",
      "           Conv2d-10         [-1, 64, 768, 768]          36,928\n",
      "             ReLU-11         [-1, 64, 768, 768]               0\n",
      "             ReLU-12         [-1, 64, 768, 768]               0\n",
      "             ReLU-13         [-1, 64, 768, 768]               0\n",
      "             ReLU-14         [-1, 64, 768, 768]               0\n",
      "             ReLU-15         [-1, 64, 768, 768]               0\n",
      "             ReLU-16         [-1, 64, 768, 768]               0\n",
      "        MaxPool2d-17         [-1, 64, 384, 384]               0\n",
      "           Conv2d-18        [-1, 128, 384, 384]          73,856\n",
      "           Conv2d-19        [-1, 128, 384, 384]          73,856\n",
      "             ReLU-20        [-1, 128, 384, 384]               0\n",
      "             ReLU-21        [-1, 128, 384, 384]               0\n",
      "             ReLU-22        [-1, 128, 384, 384]               0\n",
      "             ReLU-23        [-1, 128, 384, 384]               0\n",
      "             ReLU-24        [-1, 128, 384, 384]               0\n",
      "             ReLU-25        [-1, 128, 384, 384]               0\n",
      "           Conv2d-26        [-1, 128, 384, 384]         147,584\n",
      "           Conv2d-27        [-1, 128, 384, 384]         147,584\n",
      "             ReLU-28        [-1, 128, 384, 384]               0\n",
      "             ReLU-29        [-1, 128, 384, 384]               0\n",
      "             ReLU-30        [-1, 128, 384, 384]               0\n",
      "             ReLU-31        [-1, 128, 384, 384]               0\n",
      "             ReLU-32        [-1, 128, 384, 384]               0\n",
      "             ReLU-33        [-1, 128, 384, 384]               0\n",
      "        MaxPool2d-34        [-1, 128, 192, 192]               0\n",
      "           Conv2d-35        [-1, 256, 192, 192]         295,168\n",
      "           Conv2d-36        [-1, 256, 192, 192]         295,168\n",
      "             ReLU-37        [-1, 256, 192, 192]               0\n",
      "             ReLU-38        [-1, 256, 192, 192]               0\n",
      "             ReLU-39        [-1, 256, 192, 192]               0\n",
      "             ReLU-40        [-1, 256, 192, 192]               0\n",
      "             ReLU-41        [-1, 256, 192, 192]               0\n",
      "             ReLU-42        [-1, 256, 192, 192]               0\n",
      "           Conv2d-43        [-1, 256, 192, 192]         590,080\n",
      "           Conv2d-44        [-1, 256, 192, 192]         590,080\n",
      "             ReLU-45        [-1, 256, 192, 192]               0\n",
      "             ReLU-46        [-1, 256, 192, 192]               0\n",
      "             ReLU-47        [-1, 256, 192, 192]               0\n",
      "             ReLU-48        [-1, 256, 192, 192]               0\n",
      "             ReLU-49        [-1, 256, 192, 192]               0\n",
      "             ReLU-50        [-1, 256, 192, 192]               0\n",
      "           Conv2d-51        [-1, 256, 192, 192]         590,080\n",
      "           Conv2d-52        [-1, 256, 192, 192]         590,080\n",
      "             ReLU-53        [-1, 256, 192, 192]               0\n",
      "             ReLU-54        [-1, 256, 192, 192]               0\n",
      "             ReLU-55        [-1, 256, 192, 192]               0\n",
      "             ReLU-56        [-1, 256, 192, 192]               0\n",
      "             ReLU-57        [-1, 256, 192, 192]               0\n",
      "             ReLU-58        [-1, 256, 192, 192]               0\n",
      "        MaxPool2d-59          [-1, 256, 96, 96]               0\n",
      "           Conv2d-60          [-1, 512, 96, 96]       1,180,160\n",
      "           Conv2d-61          [-1, 512, 96, 96]       1,180,160\n",
      "             ReLU-62          [-1, 512, 96, 96]               0\n",
      "             ReLU-63          [-1, 512, 96, 96]               0\n",
      "             ReLU-64          [-1, 512, 96, 96]               0\n",
      "             ReLU-65          [-1, 512, 96, 96]               0\n",
      "             ReLU-66          [-1, 512, 96, 96]               0\n",
      "             ReLU-67          [-1, 512, 96, 96]               0\n",
      "           Conv2d-68          [-1, 512, 96, 96]       2,359,808\n",
      "           Conv2d-69          [-1, 512, 96, 96]       2,359,808\n",
      "             ReLU-70          [-1, 512, 96, 96]               0\n",
      "             ReLU-71          [-1, 512, 96, 96]               0\n",
      "             ReLU-72          [-1, 512, 96, 96]               0\n",
      "             ReLU-73          [-1, 512, 96, 96]               0\n",
      "             ReLU-74          [-1, 512, 96, 96]               0\n",
      "             ReLU-75          [-1, 512, 96, 96]               0\n",
      "           Conv2d-76          [-1, 512, 96, 96]       2,359,808\n",
      "           Conv2d-77          [-1, 512, 96, 96]       2,359,808\n",
      "             ReLU-78          [-1, 512, 96, 96]               0\n",
      "             ReLU-79          [-1, 512, 96, 96]               0\n",
      "             ReLU-80          [-1, 512, 96, 96]               0\n",
      "             ReLU-81          [-1, 512, 96, 96]               0\n",
      "             ReLU-82          [-1, 512, 96, 96]               0\n",
      "             ReLU-83          [-1, 512, 96, 96]               0\n",
      "        MaxPool2d-84          [-1, 512, 48, 48]               0\n",
      "           Conv2d-85          [-1, 512, 48, 48]       2,359,808\n",
      "           Conv2d-86          [-1, 512, 48, 48]       2,359,808\n",
      "             ReLU-87          [-1, 512, 48, 48]               0\n",
      "             ReLU-88          [-1, 512, 48, 48]               0\n",
      "             ReLU-89          [-1, 512, 48, 48]               0\n",
      "             ReLU-90          [-1, 512, 48, 48]               0\n",
      "             ReLU-91          [-1, 512, 48, 48]               0\n",
      "             ReLU-92          [-1, 512, 48, 48]               0\n",
      "           Conv2d-93          [-1, 512, 48, 48]       2,359,808\n",
      "           Conv2d-94          [-1, 512, 48, 48]       2,359,808\n",
      "             ReLU-95          [-1, 512, 48, 48]               0\n",
      "             ReLU-96          [-1, 512, 48, 48]               0\n",
      "             ReLU-97          [-1, 512, 48, 48]               0\n",
      "             ReLU-98          [-1, 512, 48, 48]               0\n",
      "             ReLU-99          [-1, 512, 48, 48]               0\n",
      "            ReLU-100          [-1, 512, 48, 48]               0\n",
      "          Conv2d-101          [-1, 512, 48, 48]       2,359,808\n",
      "          Conv2d-102          [-1, 512, 48, 48]       2,359,808\n",
      "            ReLU-103          [-1, 512, 48, 48]               0\n",
      "            ReLU-104          [-1, 512, 48, 48]               0\n",
      "            ReLU-105          [-1, 512, 48, 48]               0\n",
      "            ReLU-106          [-1, 512, 48, 48]               0\n",
      "            ReLU-107          [-1, 512, 48, 48]               0\n",
      "            ReLU-108          [-1, 512, 48, 48]               0\n",
      "       MaxPool2d-109          [-1, 512, 24, 24]               0\n",
      "     Interpolate-110          [-1, 512, 48, 48]               0\n",
      "          Conv2d-111          [-1, 512, 48, 48]       2,359,808\n",
      "            ReLU-112          [-1, 512, 48, 48]               0\n",
      "        ConvRelu-113          [-1, 512, 48, 48]               0\n",
      "          Conv2d-114          [-1, 256, 48, 48]       1,179,904\n",
      "            ReLU-115          [-1, 256, 48, 48]               0\n",
      "        ConvRelu-116          [-1, 256, 48, 48]               0\n",
      "  DecoderBlockV2-117          [-1, 256, 48, 48]               0\n",
      "     Interpolate-118          [-1, 768, 96, 96]               0\n",
      "          Conv2d-119          [-1, 512, 96, 96]       3,539,456\n",
      "            ReLU-120          [-1, 512, 96, 96]               0\n",
      "        ConvRelu-121          [-1, 512, 96, 96]               0\n",
      "          Conv2d-122          [-1, 256, 96, 96]       1,179,904\n",
      "            ReLU-123          [-1, 256, 96, 96]               0\n",
      "        ConvRelu-124          [-1, 256, 96, 96]               0\n",
      "  DecoderBlockV2-125          [-1, 256, 96, 96]               0\n",
      "     Interpolate-126        [-1, 768, 192, 192]               0\n",
      "          Conv2d-127        [-1, 512, 192, 192]       3,539,456\n",
      "            ReLU-128        [-1, 512, 192, 192]               0\n",
      "        ConvRelu-129        [-1, 512, 192, 192]               0\n",
      "          Conv2d-130        [-1, 256, 192, 192]       1,179,904\n",
      "            ReLU-131        [-1, 256, 192, 192]               0\n",
      "        ConvRelu-132        [-1, 256, 192, 192]               0\n",
      "  DecoderBlockV2-133        [-1, 256, 192, 192]               0\n",
      "     Interpolate-134        [-1, 512, 384, 384]               0\n",
      "          Conv2d-135        [-1, 256, 384, 384]       1,179,904\n",
      "            ReLU-136        [-1, 256, 384, 384]               0\n",
      "        ConvRelu-137        [-1, 256, 384, 384]               0\n",
      "          Conv2d-138         [-1, 64, 384, 384]         147,520\n",
      "            ReLU-139         [-1, 64, 384, 384]               0\n",
      "        ConvRelu-140         [-1, 64, 384, 384]               0\n",
      "  DecoderBlockV2-141         [-1, 64, 384, 384]               0\n",
      "     Interpolate-142        [-1, 192, 768, 768]               0\n",
      "          Conv2d-143        [-1, 128, 768, 768]         221,312\n",
      "            ReLU-144        [-1, 128, 768, 768]               0\n",
      "        ConvRelu-145        [-1, 128, 768, 768]               0\n",
      "          Conv2d-146         [-1, 32, 768, 768]          36,896\n",
      "            ReLU-147         [-1, 32, 768, 768]               0\n",
      "        ConvRelu-148         [-1, 32, 768, 768]               0\n",
      "  DecoderBlockV2-149         [-1, 32, 768, 768]               0\n",
      "          Conv2d-150         [-1, 32, 768, 768]          27,680\n",
      "            ReLU-151         [-1, 32, 768, 768]               0\n",
      "        ConvRelu-152         [-1, 32, 768, 768]               0\n",
      "          Conv2d-153          [-1, 1, 768, 768]              33\n",
      "================================================================\n",
      "Total params: 44,021,153\n",
      "Trainable params: 44,021,153\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 6.75\n",
      "Forward/backward pass size (MB): 16413.75\n",
      "Params size (MB): 167.93\n",
      "Estimated Total Size (MB): 16588.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 768 , 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0f677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
